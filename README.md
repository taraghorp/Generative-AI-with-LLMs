# Generative-AI-with-LLMs
## by DeepLearning.AI & Amazon Web Services

In Generative AI with Large Language Models (LLMs), you’ll learn the fundamentals of how generative AI works, and how to deploy it in real-world applications.

By taking this course, you'll learn to:
- Deeply understand generative AI, describing the key steps in a typical LLM-based generative AI lifecycle, from data gathering and model selection, to performance evaluation and deployment
- Describe in detail the transformer architecture that powers LLMs, how they’re trained, and how fine-tuning enables LLMs to be adapted to a variety of specific use cases
- Use empirical scaling laws to optimize the model's objective function across dataset size, compute budget, and inference requirements
- Apply state-of-the art training, tuning, inference, tools, and deployment methods to maximize the performance of models within the specific constraints of your project 
- Discuss the challenges and opportunities that generative AI creates for businesses after hearing stories from industry researchers and practitioners

Developers who have a good foundational understanding of how LLMs work, as well the best practices behind training and deploying them, will be able to make good decisions for their companies and more quickly build working prototypes. This course will support learners in building practical intuition about how to best utilize this exciting new technology.

This is an intermediate course, so you should have some experience coding in Python to get the most out of it. You should also be familiar with the basics of machine learning, such as supervised and unsupervised learning, loss functions, and splitting data into training, validation, and test sets. If you have taken the Machine Learning Specialization or Deep Learning Specialization from DeepLearning.AI, you’ll be ready to take this course and dive deeper into the fundamentals of generative AI.

Week 1
Generative AI use cases, project lifecycle, and model pre-training
17 videos, 5 readings
Video: Course Introduction
Reading: Contributor Acknowledgments
Video: Introduction - Week 1
Video: Generative AI & LLMs
App Item: [IMPORTANT] Have questions, issues or ideas? Join our Community!
Video: LLM use cases and tasks
Video: Text generation before transformers
Video: Transformers architecture
Video: Generating text with transformers
Reading: Transformers: Attention is all you need
Video: Prompting and prompt engineering
Video: Generative configuration
Video: Generative AI project lifecycle
Video: Introduction to AWS labs
Video: Lab 1 walkthrough
Video: Pre-training large language models
Video: Computational challenges of training LLMs
Video: Optional video: Efficient multi-GPU compute strategies
Video: Scaling laws and compute-optimal models
Video: Pre-training for domain adaptation
Reading: Domain-specific training: BloombergGPT
Reading: Week 1 resources
Reading: Lecture Notes Week 1


Graded: Lab 1 - Generative AI Use Case: Summarize Dialogue
Graded: Week 1 quiz

Week 2
Fine-tuning and evaluating large language models
10 videos, 3 readings
Video: Introduction - Week 2
Video: Instruction fine-tuning
Video: Fine-tuning on a single task
Video: Multi-task instruction fine-tuning
Reading: Scaling instruct models
Video: Model evaluation
Video: Benchmarks
Video: Parameter efficient fine-tuning (PEFT)
Video: PEFT techniques 1: LoRA
Video: PEFT techniques 2: Soft prompts
Video: Lab 2 walkthrough
Reading: Week 2 Resources
Reading: Lecture Notes Week 2


Graded: Lab 2 - Fine-tune a generative AI model for dialogue summarization
Graded: Week 2 quiz

Week 3
Reinforcement learning and LLM-powered applications
21 videos, 6 readings
Video: Introduction - Week 3
Video: Aligning models with human values
Video: Reinforcement learning from human feedback (RLHF)
Video: RLHF: Obtaining feedback from humans
Video: RLHF: Reward model
Video: RLHF: Fine-tuning with reinforcement learning
Video: Optional video: Proximal policy optimization
Video: RLHF: Reward hacking
Reading: KL divergence
Video: Scaling human feedback
Video: Lab 3 walkthrough
Video: Model optimizations for deployment
Video: Generative AI Project Lifecycle Cheat Sheet
Video: Using the LLM in applications
Video: Interacting with external applications
Video: Helping LLMs reason and plan with chain-of-thought
Video: Program-aided language models (PAL)
Video: ReAct: Combining reasoning and action
Reading: ReAct: Reasoning and action
Video: LLM application architectures
Video: Optional video: AWS Sagemaker JumpStart
Reading: Week 3 resources
Video: Responsible AI
Video: Course conclusion
Reading: Lecture Notes Week 3
Reading: Acknowledgments
Reading: (Optional) Opportunity to Mentor Other Learners


Graded: Lab 3 - Fine-tune FLAN-T5 with reinforcement learning to generate more-positive summaries
Graded: Week 3 Quiz
